{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 20:04:29.697299: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-05 20:04:29.697560: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-05 20:04:29.699609: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-05 20:04:29.723078: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-05 20:04:30.216631: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ds_clean import clean_ds\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tets = clean_ds(pd.read_csv('../data/aapl_5m_train.csv')).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Gmtoffset</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>X_t-1</th>\n",
       "      <th>...</th>\n",
       "      <th>Keltner_High_10</th>\n",
       "      <th>Keltner_Low_10</th>\n",
       "      <th>Keltner_Center_40</th>\n",
       "      <th>Keltner_High_40</th>\n",
       "      <th>Keltner_Low_40</th>\n",
       "      <th>ROC_10</th>\n",
       "      <th>ROC_20</th>\n",
       "      <th>ROC_30</th>\n",
       "      <th>Y_BUY</th>\n",
       "      <th>Y_SELL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>133</td>\n",
       "      <td>1609873500</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-05 19:05:00</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>131.149993</td>\n",
       "      <td>130.929992</td>\n",
       "      <td>131.080993</td>\n",
       "      <td>875214.0</td>\n",
       "      <td>131.005004</td>\n",
       "      <td>...</td>\n",
       "      <td>131.009289</td>\n",
       "      <td>130.171092</td>\n",
       "      <td>130.334091</td>\n",
       "      <td>130.970467</td>\n",
       "      <td>129.697715</td>\n",
       "      <td>0.770300</td>\n",
       "      <td>0.715399</td>\n",
       "      <td>0.472155</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>134</td>\n",
       "      <td>1609873800</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-05 19:10:00</td>\n",
       "      <td>131.083297</td>\n",
       "      <td>131.179992</td>\n",
       "      <td>131.029998</td>\n",
       "      <td>131.130004</td>\n",
       "      <td>753171.0</td>\n",
       "      <td>131.080993</td>\n",
       "      <td>...</td>\n",
       "      <td>131.095526</td>\n",
       "      <td>130.281151</td>\n",
       "      <td>130.372916</td>\n",
       "      <td>131.000882</td>\n",
       "      <td>129.744950</td>\n",
       "      <td>0.840532</td>\n",
       "      <td>0.706549</td>\n",
       "      <td>0.647341</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>135</td>\n",
       "      <td>1609874100</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-05 19:15:00</td>\n",
       "      <td>131.125000</td>\n",
       "      <td>131.240005</td>\n",
       "      <td>131.050003</td>\n",
       "      <td>131.229995</td>\n",
       "      <td>946361.0</td>\n",
       "      <td>131.130004</td>\n",
       "      <td>...</td>\n",
       "      <td>131.191291</td>\n",
       "      <td>130.382352</td>\n",
       "      <td>130.414725</td>\n",
       "      <td>131.036492</td>\n",
       "      <td>129.792958</td>\n",
       "      <td>0.911221</td>\n",
       "      <td>0.709875</td>\n",
       "      <td>0.628780</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>136</td>\n",
       "      <td>1609874400</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-05 19:20:00</td>\n",
       "      <td>131.222396</td>\n",
       "      <td>131.250000</td>\n",
       "      <td>131.059997</td>\n",
       "      <td>131.125000</td>\n",
       "      <td>827361.0</td>\n",
       "      <td>131.229995</td>\n",
       "      <td>...</td>\n",
       "      <td>131.250331</td>\n",
       "      <td>130.446285</td>\n",
       "      <td>130.449372</td>\n",
       "      <td>131.065095</td>\n",
       "      <td>129.833649</td>\n",
       "      <td>0.660193</td>\n",
       "      <td>0.759430</td>\n",
       "      <td>0.540563</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>137</td>\n",
       "      <td>1609874700</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-05 19:25:00</td>\n",
       "      <td>131.134994</td>\n",
       "      <td>131.184997</td>\n",
       "      <td>131.029998</td>\n",
       "      <td>131.110000</td>\n",
       "      <td>846373.0</td>\n",
       "      <td>131.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>131.288709</td>\n",
       "      <td>130.503068</td>\n",
       "      <td>130.481598</td>\n",
       "      <td>131.089678</td>\n",
       "      <td>129.873518</td>\n",
       "      <td>0.590766</td>\n",
       "      <td>0.875420</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12062</th>\n",
       "      <td>12062</td>\n",
       "      <td>1628793300</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-08-12 18:35:00</td>\n",
       "      <td>148.729995</td>\n",
       "      <td>148.850006</td>\n",
       "      <td>148.710006</td>\n",
       "      <td>148.755004</td>\n",
       "      <td>721431.0</td>\n",
       "      <td>148.740005</td>\n",
       "      <td>...</td>\n",
       "      <td>148.827876</td>\n",
       "      <td>148.261114</td>\n",
       "      <td>148.189722</td>\n",
       "      <td>148.555935</td>\n",
       "      <td>147.823509</td>\n",
       "      <td>0.327106</td>\n",
       "      <td>0.306616</td>\n",
       "      <td>0.670059</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12063</th>\n",
       "      <td>12063</td>\n",
       "      <td>1628793600</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-08-12 18:40:00</td>\n",
       "      <td>148.755004</td>\n",
       "      <td>148.756103</td>\n",
       "      <td>148.619995</td>\n",
       "      <td>148.634994</td>\n",
       "      <td>521323.0</td>\n",
       "      <td>148.755004</td>\n",
       "      <td>...</td>\n",
       "      <td>148.843214</td>\n",
       "      <td>148.278685</td>\n",
       "      <td>148.211443</td>\n",
       "      <td>148.575305</td>\n",
       "      <td>147.847580</td>\n",
       "      <td>0.188736</td>\n",
       "      <td>0.269838</td>\n",
       "      <td>0.354462</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12066</th>\n",
       "      <td>12066</td>\n",
       "      <td>1628794500</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-08-12 18:55:00</td>\n",
       "      <td>148.785003</td>\n",
       "      <td>148.800003</td>\n",
       "      <td>148.669998</td>\n",
       "      <td>148.705001</td>\n",
       "      <td>515231.0</td>\n",
       "      <td>148.789993</td>\n",
       "      <td>...</td>\n",
       "      <td>148.915832</td>\n",
       "      <td>148.348247</td>\n",
       "      <td>148.281716</td>\n",
       "      <td>148.639957</td>\n",
       "      <td>147.923475</td>\n",
       "      <td>0.266264</td>\n",
       "      <td>0.410005</td>\n",
       "      <td>0.361074</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12067</th>\n",
       "      <td>12067</td>\n",
       "      <td>1628794800</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-08-12 19:00:00</td>\n",
       "      <td>148.710006</td>\n",
       "      <td>148.785003</td>\n",
       "      <td>148.675003</td>\n",
       "      <td>148.770004</td>\n",
       "      <td>487461.0</td>\n",
       "      <td>148.705001</td>\n",
       "      <td>...</td>\n",
       "      <td>148.934537</td>\n",
       "      <td>148.379711</td>\n",
       "      <td>148.305535</td>\n",
       "      <td>148.660320</td>\n",
       "      <td>147.950750</td>\n",
       "      <td>0.229134</td>\n",
       "      <td>0.415110</td>\n",
       "      <td>0.275687</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12068</th>\n",
       "      <td>12068</td>\n",
       "      <td>1628795100</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-08-12 19:05:00</td>\n",
       "      <td>148.764999</td>\n",
       "      <td>148.860000</td>\n",
       "      <td>148.764999</td>\n",
       "      <td>148.837097</td>\n",
       "      <td>328408.0</td>\n",
       "      <td>148.770004</td>\n",
       "      <td>...</td>\n",
       "      <td>148.958519</td>\n",
       "      <td>148.421175</td>\n",
       "      <td>148.331465</td>\n",
       "      <td>148.682130</td>\n",
       "      <td>147.980800</td>\n",
       "      <td>0.193264</td>\n",
       "      <td>0.402860</td>\n",
       "      <td>0.308056</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9924 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   Timestamp  Gmtoffset             Datetime        Open  \\\n",
       "133           133  1609873500          0  2021-01-05 19:05:00  131.000000   \n",
       "134           134  1609873800          0  2021-01-05 19:10:00  131.083297   \n",
       "135           135  1609874100          0  2021-01-05 19:15:00  131.125000   \n",
       "136           136  1609874400          0  2021-01-05 19:20:00  131.222396   \n",
       "137           137  1609874700          0  2021-01-05 19:25:00  131.134994   \n",
       "...           ...         ...        ...                  ...         ...   \n",
       "12062       12062  1628793300          0  2021-08-12 18:35:00  148.729995   \n",
       "12063       12063  1628793600          0  2021-08-12 18:40:00  148.755004   \n",
       "12066       12066  1628794500          0  2021-08-12 18:55:00  148.785003   \n",
       "12067       12067  1628794800          0  2021-08-12 19:00:00  148.710006   \n",
       "12068       12068  1628795100          0  2021-08-12 19:05:00  148.764999   \n",
       "\n",
       "             High         Low       Close    Volume       X_t-1  ...  \\\n",
       "133    131.149993  130.929992  131.080993  875214.0  131.005004  ...   \n",
       "134    131.179992  131.029998  131.130004  753171.0  131.080993  ...   \n",
       "135    131.240005  131.050003  131.229995  946361.0  131.130004  ...   \n",
       "136    131.250000  131.059997  131.125000  827361.0  131.229995  ...   \n",
       "137    131.184997  131.029998  131.110000  846373.0  131.125000  ...   \n",
       "...           ...         ...         ...       ...         ...  ...   \n",
       "12062  148.850006  148.710006  148.755004  721431.0  148.740005  ...   \n",
       "12063  148.756103  148.619995  148.634994  521323.0  148.755004  ...   \n",
       "12066  148.800003  148.669998  148.705001  515231.0  148.789993  ...   \n",
       "12067  148.785003  148.675003  148.770004  487461.0  148.705001  ...   \n",
       "12068  148.860000  148.764999  148.837097  328408.0  148.770004  ...   \n",
       "\n",
       "       Keltner_High_10  Keltner_Low_10  Keltner_Center_40  Keltner_High_40  \\\n",
       "133         131.009289      130.171092         130.334091       130.970467   \n",
       "134         131.095526      130.281151         130.372916       131.000882   \n",
       "135         131.191291      130.382352         130.414725       131.036492   \n",
       "136         131.250331      130.446285         130.449372       131.065095   \n",
       "137         131.288709      130.503068         130.481598       131.089678   \n",
       "...                ...             ...                ...              ...   \n",
       "12062       148.827876      148.261114         148.189722       148.555935   \n",
       "12063       148.843214      148.278685         148.211443       148.575305   \n",
       "12066       148.915832      148.348247         148.281716       148.639957   \n",
       "12067       148.934537      148.379711         148.305535       148.660320   \n",
       "12068       148.958519      148.421175         148.331465       148.682130   \n",
       "\n",
       "       Keltner_Low_40    ROC_10    ROC_20    ROC_30  Y_BUY  Y_SELL  \n",
       "133        129.697715  0.770300  0.715399  0.472155   True   False  \n",
       "134        129.744950  0.840532  0.706549  0.647341   True   False  \n",
       "135        129.792958  0.911221  0.709875  0.628780   True   False  \n",
       "136        129.833649  0.660193  0.759430  0.540563   True   False  \n",
       "137        129.873518  0.590766  0.875420  0.629371  False    True  \n",
       "...               ...       ...       ...       ...    ...     ...  \n",
       "12062      147.823509  0.327106  0.306616  0.670059   True   False  \n",
       "12063      147.847580  0.188736  0.269838  0.354462   True   False  \n",
       "12066      147.923475  0.266264  0.410005  0.361074   True   False  \n",
       "12067      147.950750  0.229134  0.415110  0.275687  False    True  \n",
       "12068      147.980800  0.193264  0.402860  0.308056  False    True  \n",
       "\n",
       "[9924 rows x 93 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "closes = df_tets[[\n",
    "    'Close', 'X_t-1', 'X_t-2', 'X_t-3', 'X_t-4', 'X_t-5',\n",
    "    'RSI_5', 'RSI_10', 'RSI_15', 'RSI_28', 'RSI_32',\n",
    "    'EMA_5', 'EMA_10', 'EMA_15', 'EMA_28', 'EMA_32',\n",
    "    'MACD_line_12_26_9', 'MACD_signal_12_26_9', 'MACD_diff_12_26_9',\n",
    "    'MACD_line_5_35_5', 'MACD_signal_5_35_5', 'MACD_diff_5_35_5',\n",
    "    'MACD_line_7_14_3', 'MACD_signal_7_14_3', 'MACD_diff_7_14_3',\n",
    "    'Bollinger_mavg_20', 'Bollinger_hband_20', 'Bollinger_lband_20',\n",
    "    'Bollinger_mavg_10', 'Bollinger_hband_10', 'Bollinger_lband_10',\n",
    "    'Bollinger_mavg_30', 'Bollinger_hband_30', 'Bollinger_lband_30',\n",
    "    'Stoch_%K_14', 'Stoch_%D_14',\n",
    "    'Stoch_%K_10', 'Stoch_%D_10',\n",
    "    'Stoch_%K_20', 'Stoch_%D_20',\n",
    "    'ATR_14', 'ATR_10', 'ATR_20',\n",
    "    'CCI_10', 'CCI_20', 'CCI_40',  # CCI with different windows\n",
    "    'SAR_0.02_0.2', 'SAR_0.01_0.1', 'SAR_0.03_0.3',  # Parabolic SAR with different step/max_step\n",
    "    'Ichimoku_A_9_26_52', 'Ichimoku_B_9_26_52',  # Ichimoku Cloud with one setting\n",
    "    'Ichimoku_A_7_22_44', 'Ichimoku_B_7_22_44',  # Another setting\n",
    "    'Ichimoku_A_12_30_60', 'Ichimoku_B_12_30_60',  # And another setting  \n",
    "    'MFI_10', 'MFI_14', 'MFI_20',  # Money Flow Index with different windows\n",
    "    'CMF_10', 'CMF_20', 'CMF_30',  # Chaikin Money Flow with different windows\n",
    "    'Williams_7', 'Williams_14', 'Williams_28',\n",
    "    'Ultimate_Osc_7_14_28', 'Ultimate_Osc_5_10_20', 'Ultimate_Osc_10_20_30',\n",
    "    'TRIX_15', 'TRIX_30', 'TRIX_45',\n",
    "    'Keltner_Center_20', 'Keltner_High_20', 'Keltner_Low_20',\n",
    "    'Keltner_Center_10', 'Keltner_High_10', 'Keltner_Low_10',\n",
    "    'Keltner_Center_40', 'Keltner_High_40', 'Keltner_Low_40',\n",
    "    'ROC_10', 'ROC_20', 'ROC_30',\n",
    "]]\n",
    "scaler = StandardScaler()\n",
    "closes_scaled = (scaler.fit_transform(closes))\n",
    "y_buy = (df_tets['Y_BUY'].astype(int)).values.reshape(-1,1)\n",
    "y_sell = (df_tets['Y_SELL'].astype(int)).values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>X_t-1</th>\n",
       "      <th>X_t-2</th>\n",
       "      <th>X_t-3</th>\n",
       "      <th>X_t-4</th>\n",
       "      <th>X_t-5</th>\n",
       "      <th>RSI_5</th>\n",
       "      <th>RSI_10</th>\n",
       "      <th>RSI_15</th>\n",
       "      <th>RSI_28</th>\n",
       "      <th>...</th>\n",
       "      <th>Keltner_Low_20</th>\n",
       "      <th>Keltner_Center_10</th>\n",
       "      <th>Keltner_High_10</th>\n",
       "      <th>Keltner_Low_10</th>\n",
       "      <th>Keltner_Center_40</th>\n",
       "      <th>Keltner_High_40</th>\n",
       "      <th>Keltner_Low_40</th>\n",
       "      <th>ROC_10</th>\n",
       "      <th>ROC_20</th>\n",
       "      <th>ROC_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>131.080993</td>\n",
       "      <td>131.005004</td>\n",
       "      <td>130.625000</td>\n",
       "      <td>130.509994</td>\n",
       "      <td>130.523300</td>\n",
       "      <td>130.389999</td>\n",
       "      <td>95.128148</td>\n",
       "      <td>82.369533</td>\n",
       "      <td>72.186671</td>\n",
       "      <td>61.088710</td>\n",
       "      <td>...</td>\n",
       "      <td>129.934875</td>\n",
       "      <td>130.590190</td>\n",
       "      <td>131.009289</td>\n",
       "      <td>130.171092</td>\n",
       "      <td>130.334091</td>\n",
       "      <td>130.970467</td>\n",
       "      <td>129.697715</td>\n",
       "      <td>0.770300</td>\n",
       "      <td>0.715399</td>\n",
       "      <td>0.472155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>131.130004</td>\n",
       "      <td>131.080993</td>\n",
       "      <td>131.005004</td>\n",
       "      <td>130.625000</td>\n",
       "      <td>130.509994</td>\n",
       "      <td>130.523300</td>\n",
       "      <td>95.555460</td>\n",
       "      <td>83.200522</td>\n",
       "      <td>73.023139</td>\n",
       "      <td>61.612956</td>\n",
       "      <td>...</td>\n",
       "      <td>130.011250</td>\n",
       "      <td>130.688338</td>\n",
       "      <td>131.095526</td>\n",
       "      <td>130.281151</td>\n",
       "      <td>130.372916</td>\n",
       "      <td>131.000882</td>\n",
       "      <td>129.744950</td>\n",
       "      <td>0.840532</td>\n",
       "      <td>0.706549</td>\n",
       "      <td>0.647341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>131.229995</td>\n",
       "      <td>131.130004</td>\n",
       "      <td>131.080993</td>\n",
       "      <td>131.005004</td>\n",
       "      <td>130.625000</td>\n",
       "      <td>130.509994</td>\n",
       "      <td>96.367892</td>\n",
       "      <td>84.822202</td>\n",
       "      <td>74.687193</td>\n",
       "      <td>62.676852</td>\n",
       "      <td>...</td>\n",
       "      <td>130.086318</td>\n",
       "      <td>130.786821</td>\n",
       "      <td>131.191291</td>\n",
       "      <td>130.382352</td>\n",
       "      <td>130.414725</td>\n",
       "      <td>131.036492</td>\n",
       "      <td>129.792958</td>\n",
       "      <td>0.911221</td>\n",
       "      <td>0.709875</td>\n",
       "      <td>0.628780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>131.125000</td>\n",
       "      <td>131.229995</td>\n",
       "      <td>131.130004</td>\n",
       "      <td>131.080993</td>\n",
       "      <td>131.005004</td>\n",
       "      <td>130.625000</td>\n",
       "      <td>77.720660</td>\n",
       "      <td>76.236115</td>\n",
       "      <td>69.840409</td>\n",
       "      <td>60.840692</td>\n",
       "      <td>...</td>\n",
       "      <td>130.144478</td>\n",
       "      <td>130.848308</td>\n",
       "      <td>131.250331</td>\n",
       "      <td>130.446285</td>\n",
       "      <td>130.449372</td>\n",
       "      <td>131.065095</td>\n",
       "      <td>129.833649</td>\n",
       "      <td>0.660193</td>\n",
       "      <td>0.759430</td>\n",
       "      <td>0.540563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>131.110000</td>\n",
       "      <td>131.125000</td>\n",
       "      <td>131.229995</td>\n",
       "      <td>131.130004</td>\n",
       "      <td>131.080993</td>\n",
       "      <td>131.005004</td>\n",
       "      <td>75.124703</td>\n",
       "      <td>75.030513</td>\n",
       "      <td>69.153486</td>\n",
       "      <td>60.577766</td>\n",
       "      <td>...</td>\n",
       "      <td>130.199399</td>\n",
       "      <td>130.895889</td>\n",
       "      <td>131.288709</td>\n",
       "      <td>130.503068</td>\n",
       "      <td>130.481598</td>\n",
       "      <td>131.089678</td>\n",
       "      <td>129.873518</td>\n",
       "      <td>0.590766</td>\n",
       "      <td>0.875420</td>\n",
       "      <td>0.629371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12062</th>\n",
       "      <td>148.755004</td>\n",
       "      <td>148.740005</td>\n",
       "      <td>148.669799</td>\n",
       "      <td>148.539993</td>\n",
       "      <td>148.550003</td>\n",
       "      <td>148.429901</td>\n",
       "      <td>85.221644</td>\n",
       "      <td>73.584661</td>\n",
       "      <td>68.747882</td>\n",
       "      <td>65.042193</td>\n",
       "      <td>...</td>\n",
       "      <td>148.097720</td>\n",
       "      <td>148.544495</td>\n",
       "      <td>148.827876</td>\n",
       "      <td>148.261114</td>\n",
       "      <td>148.189722</td>\n",
       "      <td>148.555935</td>\n",
       "      <td>147.823509</td>\n",
       "      <td>0.327106</td>\n",
       "      <td>0.306616</td>\n",
       "      <td>0.670059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12063</th>\n",
       "      <td>148.634994</td>\n",
       "      <td>148.755004</td>\n",
       "      <td>148.740005</td>\n",
       "      <td>148.669799</td>\n",
       "      <td>148.539993</td>\n",
       "      <td>148.550003</td>\n",
       "      <td>59.305924</td>\n",
       "      <td>62.566890</td>\n",
       "      <td>62.233387</td>\n",
       "      <td>62.089438</td>\n",
       "      <td>...</td>\n",
       "      <td>148.120559</td>\n",
       "      <td>148.560949</td>\n",
       "      <td>148.843214</td>\n",
       "      <td>148.278685</td>\n",
       "      <td>148.211443</td>\n",
       "      <td>148.575305</td>\n",
       "      <td>147.847580</td>\n",
       "      <td>0.188736</td>\n",
       "      <td>0.269838</td>\n",
       "      <td>0.354462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12066</th>\n",
       "      <td>148.705001</td>\n",
       "      <td>148.789993</td>\n",
       "      <td>148.649902</td>\n",
       "      <td>148.634994</td>\n",
       "      <td>148.755004</td>\n",
       "      <td>148.740005</td>\n",
       "      <td>59.081869</td>\n",
       "      <td>62.386044</td>\n",
       "      <td>62.343972</td>\n",
       "      <td>62.231387</td>\n",
       "      <td>...</td>\n",
       "      <td>148.196521</td>\n",
       "      <td>148.632040</td>\n",
       "      <td>148.915832</td>\n",
       "      <td>148.348247</td>\n",
       "      <td>148.281716</td>\n",
       "      <td>148.639957</td>\n",
       "      <td>147.923475</td>\n",
       "      <td>0.266264</td>\n",
       "      <td>0.410005</td>\n",
       "      <td>0.361074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12067</th>\n",
       "      <td>148.770004</td>\n",
       "      <td>148.705001</td>\n",
       "      <td>148.789993</td>\n",
       "      <td>148.649902</td>\n",
       "      <td>148.634994</td>\n",
       "      <td>148.755004</td>\n",
       "      <td>65.868230</td>\n",
       "      <td>65.474319</td>\n",
       "      <td>64.318719</td>\n",
       "      <td>63.184358</td>\n",
       "      <td>...</td>\n",
       "      <td>148.225768</td>\n",
       "      <td>148.657124</td>\n",
       "      <td>148.934537</td>\n",
       "      <td>148.379711</td>\n",
       "      <td>148.305535</td>\n",
       "      <td>148.660320</td>\n",
       "      <td>147.950750</td>\n",
       "      <td>0.229134</td>\n",
       "      <td>0.415110</td>\n",
       "      <td>0.275687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12068</th>\n",
       "      <td>148.837097</td>\n",
       "      <td>148.770004</td>\n",
       "      <td>148.705001</td>\n",
       "      <td>148.789993</td>\n",
       "      <td>148.649902</td>\n",
       "      <td>148.634994</td>\n",
       "      <td>71.884425</td>\n",
       "      <td>68.445502</td>\n",
       "      <td>66.274595</td>\n",
       "      <td>64.152514</td>\n",
       "      <td>...</td>\n",
       "      <td>148.260341</td>\n",
       "      <td>148.689847</td>\n",
       "      <td>148.958519</td>\n",
       "      <td>148.421175</td>\n",
       "      <td>148.331465</td>\n",
       "      <td>148.682130</td>\n",
       "      <td>147.980800</td>\n",
       "      <td>0.193264</td>\n",
       "      <td>0.402860</td>\n",
       "      <td>0.308056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9924 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Close       X_t-1       X_t-2       X_t-3       X_t-4       X_t-5  \\\n",
       "133    131.080993  131.005004  130.625000  130.509994  130.523300  130.389999   \n",
       "134    131.130004  131.080993  131.005004  130.625000  130.509994  130.523300   \n",
       "135    131.229995  131.130004  131.080993  131.005004  130.625000  130.509994   \n",
       "136    131.125000  131.229995  131.130004  131.080993  131.005004  130.625000   \n",
       "137    131.110000  131.125000  131.229995  131.130004  131.080993  131.005004   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "12062  148.755004  148.740005  148.669799  148.539993  148.550003  148.429901   \n",
       "12063  148.634994  148.755004  148.740005  148.669799  148.539993  148.550003   \n",
       "12066  148.705001  148.789993  148.649902  148.634994  148.755004  148.740005   \n",
       "12067  148.770004  148.705001  148.789993  148.649902  148.634994  148.755004   \n",
       "12068  148.837097  148.770004  148.705001  148.789993  148.649902  148.634994   \n",
       "\n",
       "           RSI_5     RSI_10     RSI_15     RSI_28  ...  Keltner_Low_20  \\\n",
       "133    95.128148  82.369533  72.186671  61.088710  ...      129.934875   \n",
       "134    95.555460  83.200522  73.023139  61.612956  ...      130.011250   \n",
       "135    96.367892  84.822202  74.687193  62.676852  ...      130.086318   \n",
       "136    77.720660  76.236115  69.840409  60.840692  ...      130.144478   \n",
       "137    75.124703  75.030513  69.153486  60.577766  ...      130.199399   \n",
       "...          ...        ...        ...        ...  ...             ...   \n",
       "12062  85.221644  73.584661  68.747882  65.042193  ...      148.097720   \n",
       "12063  59.305924  62.566890  62.233387  62.089438  ...      148.120559   \n",
       "12066  59.081869  62.386044  62.343972  62.231387  ...      148.196521   \n",
       "12067  65.868230  65.474319  64.318719  63.184358  ...      148.225768   \n",
       "12068  71.884425  68.445502  66.274595  64.152514  ...      148.260341   \n",
       "\n",
       "       Keltner_Center_10  Keltner_High_10  Keltner_Low_10  Keltner_Center_40  \\\n",
       "133           130.590190       131.009289      130.171092         130.334091   \n",
       "134           130.688338       131.095526      130.281151         130.372916   \n",
       "135           130.786821       131.191291      130.382352         130.414725   \n",
       "136           130.848308       131.250331      130.446285         130.449372   \n",
       "137           130.895889       131.288709      130.503068         130.481598   \n",
       "...                  ...              ...             ...                ...   \n",
       "12062         148.544495       148.827876      148.261114         148.189722   \n",
       "12063         148.560949       148.843214      148.278685         148.211443   \n",
       "12066         148.632040       148.915832      148.348247         148.281716   \n",
       "12067         148.657124       148.934537      148.379711         148.305535   \n",
       "12068         148.689847       148.958519      148.421175         148.331465   \n",
       "\n",
       "       Keltner_High_40  Keltner_Low_40    ROC_10    ROC_20    ROC_30  \n",
       "133         130.970467      129.697715  0.770300  0.715399  0.472155  \n",
       "134         131.000882      129.744950  0.840532  0.706549  0.647341  \n",
       "135         131.036492      129.792958  0.911221  0.709875  0.628780  \n",
       "136         131.065095      129.833649  0.660193  0.759430  0.540563  \n",
       "137         131.089678      129.873518  0.590766  0.875420  0.629371  \n",
       "...                ...             ...       ...       ...       ...  \n",
       "12062       148.555935      147.823509  0.327106  0.306616  0.670059  \n",
       "12063       148.575305      147.847580  0.188736  0.269838  0.354462  \n",
       "12066       148.639957      147.923475  0.266264  0.410005  0.361074  \n",
       "12067       148.660320      147.950750  0.229134  0.415110  0.275687  \n",
       "12068       148.682130      147.980800  0.193264  0.402860  0.308056  \n",
       "\n",
       "[9924 rows x 82 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = closes.shape[1]\n",
    "X = closes_scaled.reshape(-1, features, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_buy, x_test_buy, y_train_buy, y_test_buy = train_test_split(X, y_buy, test_size=0.2, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transformer(inputs, head_size, num_heads, dnn_dim):\n",
    "    # Stacking layers\n",
    "    l1 = tf.keras.layers.MultiHeadAttention(key_dim=head_size,\n",
    "                                            num_heads=num_heads,\n",
    "                                            dropout=0.02)(inputs, inputs)\n",
    "    l2 = tf.keras.layers.Dropout(0.02)(l1)\n",
    "    l3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(l2)\n",
    "    \n",
    "    res = l3 + inputs\n",
    "    \n",
    "    # Traditional DNN\n",
    "    l4 = tf.keras.layers.Conv1D(filters=4, kernel_size=1, activation=\"leaky_relu\")(res)\n",
    "    l5 = tf.keras.layers.Dropout(0.02)(l4)\n",
    "    l6 = tf.keras.layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(l5)\n",
    "    l7 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(l6)\n",
    "    return l7 + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 20:04:41.344831: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-05 20:04:41.345076: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "input_shape = x_train_buy.shape[1:]\n",
    "\n",
    "# Hyperparams\n",
    "head_size = 256\n",
    "num_heads = 4\n",
    "num_transformer_blocks = 4\n",
    "dnn_dim = 4\n",
    "units = 1500\n",
    "\n",
    "\n",
    "# Defining input_shape as Input layer\n",
    "input_layer = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "# Creating our transformers based on the input layer\n",
    "transformer_layers = input_layer\n",
    "\n",
    "for _ in range(num_transformer_blocks):\n",
    "    # Stacking transformers\n",
    "    transformer_layers = create_transformer(inputs=transformer_layers,\n",
    "                                            head_size=head_size,\n",
    "                                            num_heads=num_heads,\n",
    "                                            dnn_dim=dnn_dim)\n",
    "\n",
    "\n",
    "# Adding global pooling\n",
    "pooling_layer = tf.keras.layers.GlobalAveragePooling1D(data_format=\"channels_last\")\\\n",
    "                                                      (transformer_layers)\n",
    "\n",
    "\n",
    "# Adding MLP layers\n",
    "l1 = tf.keras.layers.Dense(units=750, activation=\"leaky_relu\")(pooling_layer)\n",
    "l2 = tf.keras.layers.Dropout(0.01)(l1)\n",
    "l3 = tf.keras.layers.Dense(units=500, activation=\"leaky_relu\")(l2)\n",
    "# l4 = tf.keras.layers.Dropout(0.01)(l3)\n",
    "# l5 = tf.keras.layers.Dense(units=32, activation=\"leaky_relu\")(l4)\n",
    "\n",
    "# Last layer, units = 2 for True and False values\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(l3)\n",
    "\n",
    "# Model\n",
    "model = tf.keras.Model(inputs=input_layer,\n",
    "                       outputs=outputs,\n",
    "                       name=\"transformers_classification\")\n",
    "\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "sgd_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "rmsprop_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "adadelta_optimizer = tf.keras.optimizers.Adadelta(learning_rate=1.0, rho=0.95)\n",
    "nadam_optimizer = tf.keras.optimizers.Nadam(learning_rate=0.001)\n",
    "#callbacks = [tf.keras.callbacks.EarlyStopping(monitor=\"loss\",\n",
    "#                                              patience=10,\n",
    "#                                              restore_best_weights=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=adam_optimizer,\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformers_classification\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformers_classification\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ conv1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">750</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,500</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">750</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">375,500</span> │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">501</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │      \u001b[38;5;34m7,169\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m2\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m4\u001b[0m)     │          \u001b[38;5;34m8\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m4\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m5\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m2\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │      \u001b[38;5;34m7,169\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m2\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m4\u001b[0m)     │          \u001b[38;5;34m8\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m4\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m5\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m2\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │      \u001b[38;5;34m7,169\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m2\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m4\u001b[0m)     │          \u001b[38;5;34m8\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m4\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m5\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m2\u001b[0m │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │      \u001b[38;5;34m7,169\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m2\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m4\u001b[0m)     │          \u001b[38;5;34m8\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m4\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ conv1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m5\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m2\u001b[0m │ conv1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m750\u001b[0m)       │      \u001b[38;5;34m1,500\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m750\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m)       │    \u001b[38;5;34m375,500\u001b[0m │ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m501\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">406,245</span> (1.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m406,245\u001b[0m (1.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">406,245</span> (1.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m406,245\u001b[0m (1.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 125ms/step - accuracy: 0.5264 - loss: 0.6924\n",
      "Epoch 2/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 123ms/step - accuracy: 0.5118 - loss: 0.6925\n",
      "Epoch 3/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 124ms/step - accuracy: 0.5093 - loss: 0.6929\n",
      "Epoch 4/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 124ms/step - accuracy: 0.5185 - loss: 0.6931\n",
      "Epoch 5/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 125ms/step - accuracy: 0.5203 - loss: 0.6917\n",
      "Epoch 6/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 145ms/step - accuracy: 0.5075 - loss: 0.6932\n",
      "Epoch 7/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 149ms/step - accuracy: 0.5201 - loss: 0.6923\n",
      "Epoch 8/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 149ms/step - accuracy: 0.5076 - loss: 0.6926\n",
      "Epoch 9/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 151ms/step - accuracy: 0.5136 - loss: 0.6930\n",
      "Epoch 10/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 151ms/step - accuracy: 0.5245 - loss: 0.6918\n",
      "Epoch 11/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 152ms/step - accuracy: 0.5172 - loss: 0.6924\n",
      "Epoch 12/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 152ms/step - accuracy: 0.5060 - loss: 0.6929\n",
      "Epoch 13/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 152ms/step - accuracy: 0.5170 - loss: 0.6915\n",
      "Epoch 14/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 156ms/step - accuracy: 0.5097 - loss: 0.6927\n",
      "Epoch 15/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 158ms/step - accuracy: 0.5184 - loss: 0.6919\n",
      "Epoch 16/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 156ms/step - accuracy: 0.5107 - loss: 0.6928\n",
      "Epoch 17/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 156ms/step - accuracy: 0.5075 - loss: 0.6928\n",
      "Epoch 18/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 157ms/step - accuracy: 0.5237 - loss: 0.6921\n",
      "Epoch 19/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 156ms/step - accuracy: 0.5046 - loss: 0.6928\n",
      "Epoch 20/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 157ms/step - accuracy: 0.5026 - loss: 0.6929\n",
      "Epoch 21/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 156ms/step - accuracy: 0.5146 - loss: 0.6924\n",
      "Epoch 22/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 157ms/step - accuracy: 0.5151 - loss: 0.6926\n",
      "Epoch 23/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 157ms/step - accuracy: 0.5141 - loss: 0.6925\n",
      "Epoch 24/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 156ms/step - accuracy: 0.5090 - loss: 0.6926\n",
      "Epoch 25/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 157ms/step - accuracy: 0.5233 - loss: 0.6913\n",
      "Epoch 26/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 156ms/step - accuracy: 0.5167 - loss: 0.6922\n",
      "Epoch 27/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 157ms/step - accuracy: 0.5128 - loss: 0.6923\n",
      "Epoch 28/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 157ms/step - accuracy: 0.5041 - loss: 0.6927\n",
      "Epoch 29/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 157ms/step - accuracy: 0.5185 - loss: 0.6919\n",
      "Epoch 30/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 156ms/step - accuracy: 0.5033 - loss: 0.6926\n",
      "Epoch 31/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 158ms/step - accuracy: 0.5121 - loss: 0.6927\n",
      "Epoch 32/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 157ms/step - accuracy: 0.5113 - loss: 0.6922\n",
      "Epoch 33/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 157ms/step - accuracy: 0.5244 - loss: 0.6918\n",
      "Epoch 34/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 158ms/step - accuracy: 0.5131 - loss: 0.6924\n",
      "Epoch 35/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 157ms/step - accuracy: 0.5245 - loss: 0.6915\n",
      "Epoch 36/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 157ms/step - accuracy: 0.5185 - loss: 0.6918\n",
      "Epoch 37/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 157ms/step - accuracy: 0.5223 - loss: 0.6920\n",
      "Epoch 38/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 157ms/step - accuracy: 0.5245 - loss: 0.6921\n",
      "Epoch 39/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 156ms/step - accuracy: 0.5137 - loss: 0.6925\n",
      "Epoch 40/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 155ms/step - accuracy: 0.5113 - loss: 0.6919\n",
      "Epoch 41/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 157ms/step - accuracy: 0.5095 - loss: 0.6930\n",
      "Epoch 42/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 156ms/step - accuracy: 0.5076 - loss: 0.6928\n",
      "Epoch 43/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 156ms/step - accuracy: 0.5172 - loss: 0.6921\n",
      "Epoch 44/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 156ms/step - accuracy: 0.5171 - loss: 0.6919\n",
      "Epoch 45/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 155ms/step - accuracy: 0.5128 - loss: 0.6925\n",
      "Epoch 46/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 156ms/step - accuracy: 0.5210 - loss: 0.6913\n",
      "Epoch 47/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 156ms/step - accuracy: 0.5135 - loss: 0.6920\n",
      "Epoch 48/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 156ms/step - accuracy: 0.5219 - loss: 0.6914\n",
      "Epoch 49/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 156ms/step - accuracy: 0.5103 - loss: 0.6923\n",
      "Epoch 50/50\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 155ms/step - accuracy: 0.5188 - loss: 0.6920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fe2b6cd3fd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train_buy,\n",
    "    y_train_buy,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    # callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_buy.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
